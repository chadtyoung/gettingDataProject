df$VAL
df$VAL[df$VAL==24]
summary(df$VAL[df$VAL==24])
x = df$VAL[df$VAL==24]
x = na.omit(x)
x
summary(x)
len(x)
length(x)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile='quiz2_acc.xlsx', method="curl")
df1 <- read.xls("quiz1_acc.xlsx")
df1 <- read.xlsx("quiz1_acc.xlsx")
library(xlsx)
install.packages("xlsx")
library(xlsx)
df1 <- read.xlsx("quiz1_acc.xlsx")
help(read_xlsx)
?read_xlsx)
help(read.xlsx)
df1 <- read.xlsx("quiz1_acc.xlsx",0)
df1 <- read.xlsx("quiz2_acc.xlsx",0)
df1 <- read.xlsx("quiz2_acc.xlsx")
df1 <- read.xlsx("quiz2_acc.xlsx",0)
df1 <- read.xlsx("quiz2_acc.xlsx",sheetName="NGAP Sample Data"
)
df1 <- read.xlsx("quiz2_acc.xlsx",sheetName="NGAP Sample Data")
df1
df1 <- read.xlsx("quiz2_acc.xlsx",sheetName="NGAP Sample Data", startRow=18, endRow=23, colIndex=7,15)
df1
sum(df1$Zip*df1$Ext, na.rm=T)
df1$Ext
df1
df1 <- read.xlsx("quiz2_acc.xlsx",sheetName="NGAP Sample Data", startRow=18, endRow=23, colIndex=7:15)
df1
sum(df1$Zip*df1$Ext, na.rm=T)
help(read.html)
fu <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- htmlTreeParse(fu, useInternal=TRUE)
install.packages("XML")
library(XML)
doc <- htmlTreeParse(fu, useInternal=TRUE)
install.packages("htmltools")
library(RCurl)
install.packages("RCurl")
library(RCurl)
doc <- htmlTreeParse(fu, useInternal=TRUE)
doc <- xmlTreeParse(fu, useInternal=TRUE)
fu <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fu, method="curl", destfile='rest.xml')
doc <- xmlTreeParse("rest.xml", useInternal=TRUE)
doc
rn <- xmlRoot(doc)
rn
xmlName(rn)
doc
names(rn)
rn[[1]]
rn[[2]]
rn[[3]]
rn[[1]][[1]]
rn[[1]][[2]]
rn[[1]][[3]]
xmlSApply(rn, xmlValue)
v1 <- xmlSApply(rn, xmlValue)
vz <- xmlSApply(rn, "//zipcode",xmlValue)
vz <- xpathSApply(rn, "//zipcode",xmlValue)
vz
summary(vz)
vz[ vz='21212']
vz[ vz=='21212']
length(vz[ vz=='21212'])
length(vz[ vz=='21231'])
fu <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fu, method="curl", destfile='acsidaho.csv')
DT <- fread(fu)
help(fread)
install.packages("data.table")
library(data.table)
help(fread)
fu
df3 <- fread(fu)
download.file(fu, method="curl", destfile='acsidaho.csv')c
df3 <- fread("acsidaho.csv")
df3
df3$pwgtp15
fu <- download.file(fu, destfile="HARdataset.zip", method="curl")
clear all
clear
help(clear)
clr
ls
dir
df <- fread("001.csv")
df <- read.csv('001.csv')
cd specdata
setwd("specdata")
setwd("specdata")
?getwd
getwd
print getwd
print(getwd)
print(getwd())
setwd("~/Coursera_Data/Rprog_week2/specdata")
print(getwd())
df <- read.csv('001.csv')
df
head(df)
pol <- 'sulfate'
df$pol
df$silfate
df$sulfate
df$pol
df[[pol]]
for i in 1:10
i = 1:10
i
for (x in i) { print(x)}
sprintf('%03d', 20)
fn = sprintf('%03d.csv', 20)
fn = sprintf('%03d.csv', 20)
fn
for (x in i) { fn <- sprintf('%03d.csv', x)}
for (x in i) { fn <- sprintf('%03d.csv', x); print(fn)}
temp = []
temp = NULL
temp <- df[[pol]]
temp
temp <- cat[ temp, df$sulfate]
temp1 <- df[[sulfate]]
temp1 <- df$sulfate
temp <- cat[temp, temp1]
temp <- c(temp, temp1)
help(mean)
source('~/Coursera_Data/Rprog_week2/week2.r')
setwd("~/Coursera_Data/Rprog_week2")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
source('~/Coursera_Data/Rprog_week2/week2.r')
pollutantmean("specdata", "nitrate", 70:72)
source('~/Coursera_Data/Rprog_week2/week2.r')
source('~/Coursera_Data/Rprog_week2/week2.r')
pollutantmean("specdata", "nitrate", 70:72)
setwd("~/Coursera_Data/Rprog_week2")
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "nitrate", 23)
source('~/Coursera_Data/Rprog_week2/pollutantmean.R')
df <- read.csv('002.csv')
df <- read.csv('specdata/002.csv')
summary(df)
df <- read.csv('specdata/012.csv')
summary(df)
help(complete.cases)
complete('specdata', 1:10)
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
source('~/Coursera_Data/Rprog_week2/complete.R')
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
source('~/Coursera_Data/Rprog_week2/complete.R')
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', c(2,4,8,10,12))
complete('specdata', 3
complete('specdata', 3)
complete('specdata', 3)
complete('specdata', q)
complete('specdata', 1)
complete('specdata', 30:25)
source('~/Coursera_Data/Rprog_week2/complete.R')
complete('specdata', 30:25)
source('~/Coursera_Data/Rprog_week2/pollutantmean.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
list.files('specdata')
print list.files('specdata')
print(list.files('specdata'))
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
help(corr)
help(cor)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
help(cor)
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
complete('specdata', 1:10)
complete('specdata')
tf <- complete('specdata')
tf[ tf$nobs > 90]
tf[ tf[nobs] > 90]
tf[ tf[[nobs]] > 90]
tf[nobs > 90]
tf[tf[[nobs]] > 90]
tf[[nobs]] > 90]
tf[nobs] > 90]
tf[ tf$nobs > 90, ]
tf[ tf$nobs < 90, ]
tf[ tf$nobs < 90, ][id]
tf[ tf$nobs < 90, ]
id <- tf[ tf$nobs < 90, ]
id
sprintf('%03d.csv', id$id)
source('~/Coursera_Data/Rprog_week2/corr.R')
id <- tf[ tf$nobs < 90, ]
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 92)
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 150)
c1
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 150)
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 150)
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 150)
source('~/Coursera_Data/Rprog_week2/corr.R')
c1 <- corr('specdata', 150)
head(c1)
c1 <- corr('specdata', 400)
head(c1)
summary(c1)
c1 <- corr('specdata')
summary(c1)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
install.packages("httr")
t <- GET("https://api.github.com/users/jtleek/repos")
t2 <- content(t)
t3 <- jsonlite::fromJSON(toJSON(t2))
ans <- subset(t3$created_at, t3$name=="datasharing")
library(httr)
t <- GET("https://api.github.com/users/jtleek/repos")
t2 <- content(t)
t3 <- jsonlite::fromJSON(toJSON(t2))
ans <- subset(t3$created_at, t3$name=="datasharing")
t2
t3
install.packages("jsonlite")
ans <- subset(t3$created_at, t3$name=="datasharing")
library(jsonlite)
library(httr)
t <- GET("https://api.github.com/users/jtleek/repos")
t2 <- content(t)
t3 <- jsonlite::fromJSON(toJSON(t2))
ans <- subset(t3$created_at, t3$name=="datasharing")
ans
install.packages("sqldf")
ans
library(XML)
doch <- htmlTreeParse('')
u <- URL("http://biostat.jhsph.edu/~jleek/contact.html ")
u <- url("http://biostat.jhsph.edu/~jleek/contact.html")
u
doc <- readLines(u)
doc
nchar(doc[10])
nchar(doc[10])
doc[10]
doc[20]
nchar(doc[20])
q <- c(10,20,30,100)
nchar(doc[q])
u <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
d <- readLines(u)
u <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", )
help(url)
u <- url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for")
d <- readLines(u)
d1 <- read.table(u, skip=2, header=2, sep=" ")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", method="curl", destfile="wks.for")
d1 <- read.table("wks.for", skip=2, header=2, sep=" ")
d1 <- read.table("wks2.for", skip=3, header=1, sep=",")
d1
summary(df)
summary(d1[,5])
sum(d1[,5])
getcwd()
print(get_cwd())
print(get_pwd())
print(getcwd())
print(getcwd
print(getcwd)
print(get_cwd)
print(get_cwd())
print(getwd())
setwd("~/coursera_github/getdata_HumanActivity")
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
features <- read.file("Data/Raw/UCI HAR Dataset/features.txt")
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
features <- readLines(ffile)
features
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
features <- read.delim(ffile, sep=" ")
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
close(ffile)
source('~/.active-rstudio-document')
features
features[,1]
features[,0]
features[,2]
features[,1]
features[,1]
features[,]
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
features <- read.delim(ffile, sep=" ", header=FALSE)
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
#close(ffile)
features[,1]
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
head(dataTest)
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
dataAll[ grep("-std", dataAll.colnames)]
dataAll.colnames
dataAll.colnames()
print(dataAll.colnames())
print(dataAll.colnames
)
dataAll[ grep("-std", colnames(dataAll))]
colnames(dataAll)
dataAll[ grep(".std", colnames(dataAll))]
dsb <- rbind(dataAll[ grep(".std", colnames(dataAll))], dataAll[ grep(".mean", colnames(dataAll))])
dsb <- cbind(dataAll[ grep(".std", colnames(dataAll))], dataAll[ grep(".mean", colnames(dataAll))])
colnames(dsb)
fdata <- file("Data/Raw/UCI HAR Dataset/activity_labels.txt")
activity <- read.table(fdata)
actv
activity
length(activity)
nrow(activity)
for (i in 1:nrow(activity)) { actString <- activity[i,2]}
for (i in 1:nrow(activity)) { actString <- activity[i,2]}
for (i in 1:nrow(activity)) { actString <- activity[i,2]
print(actString)
}
for (i in 1:nrow(activity)) { actString <- as.string(activity[i,2])
print(actString)
}
for (i in 1:nrow(activity)) { actString <- activity[i,2]
print(actString)
dsb[ dsb['activity' == activity[i,1]] <- activity[i,2]
}
for (i in 1:nrow(activity)) { actString <- activity[i,2]
print(actString)
dsb[ dsb['activity'] == activity[i,1]] <- activity[i,2]
}
dsb['activity']
colnames(dsb)
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
colnames(dataAll)
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
dsb[ dsb['activity' == activity[i,1]] <- activity[i,2]
]
for (i in 1:nrow(activity)) {
dsb[ dsb['activity' == activity[i,1]]['act'] <- activity[i,2]
}
for (i in 1:nrow(activity)) {
dsb[ dsb['activity' == activity[i,1]]['act'] <- activity[i,2]
}
for (i in 1:nrow(activity)) {
dsb[ dsb['activity'] == activity[i,1]]['act'] <- activity[i,2]
}
for (i in 1:nrow(activity)) {
dsb[ dsb['activity'] == activity[i,1]]['act'] <- activity[i,2]
}
dsb['act'] <- 10
head(dsb)
for (i in 1:nrow(activity)) {
dsb[ dsb['activity'] == activity[i,1]]['act'] <- activity[i,2]
}
head(dsb)
activity[1,1]
dsb[ dsb['activity'] == 1]
dsb[ dsb['activity'] == 1]['act'] <- 'act1'
head(dsb)
c <- dsb['activity'] == 1]
c <- dsb['activity'] == 1
c
dsb[c]['act']
dsb[c]["act"]
dsb[c]
dsb[c]
head(dsb[c])
head(dsb[c,])
c <- dsb['activity'] == 5
head(dsb[c,])
dsb[c,'act']
dsb[c,'act'] <- 'five'
head(dsb[c,])
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
head(dsb)
tail(dsb)
help(write.table)
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
a <- aggregate(. ~ subject,dataSubset, mean)
a
dataSubset['activitynum'] <- as.factor(dataSubset['activitynum'])
a <- aggregate(. ~ c(subject, activity),dataSubset, mean)
a <- aggregate(. ~ [subject, activity],dataSubset, mean)
a <- aggregate(. ~ ['subject'', 'activity''],dataSubset, mean)
a <- aggregate(. ~ subject+activity,dataSubset, mean)
head(a)
dataSubset['activitynum'] <- NULL
a <- aggregate(. ~ subject+activity,dataSubset, mean)
head(a)
tail(a)
a <- aggregate(. ~ subject,dataSubset, mean)
tail(a)
a <- aggregate(. ~ activity+subject,dataSubset, mean)
tail(a)
a <- aggregate(. ~ activity,dataSubset, mean)
a <- aggregate(. ~ subject,dataSubset, mean)
a
a <- aggregate(. ~ activity,dataSubset, mean)
a
a <- aggregate(. ~ activity,dat
aSubset, mean)
a <- aggregate(. ~ activity+subject,dataSubset, mean)
a
head(a)
head(a[,1:5])
a[,1:5])
a[,1:5]
source('~/coursera_github/getdata_HumanActivity/Get and clean Samsung Data.R')
